{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734198af",
   "metadata": {},
   "source": [
    "<h1>Introduction to Large Language Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c9461",
   "metadata": {},
   "source": [
    "<h3>🔍 1. Large Language Model (LLM) là gì?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0551829",
   "metadata": {},
   "source": [
    "LLM là mô hình ngôn ngữ lớn có khả năng hiểu và sinh ngôn ngữ tự nhiên, ứng dụng rộng rãi trong chatbot, xử lý văn bản, hỗ trợ học tập và lập trình. Chúng học từ dữ liệu văn bản khổng lồ và sử dụng kiến trúc Transformer để tạo ra phản hồi thông minh gần giống con người."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ce488",
   "metadata": {},
   "source": [
    "LLM có thể:\n",
    "\n",
    "- Trả lời câu hỏi\n",
    "\n",
    "- Viết văn bản (thơ, văn, tin tức, email…)\n",
    "\n",
    "- Viết code\n",
    "\n",
    "- Tóm tắt, dịch, phân tích văn bản\n",
    "\n",
    "- Giao tiếp qua hội thoại tự nhiên\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acea383",
   "metadata": {},
   "source": [
    "<h3>🧠 2. Cách LLM hoạt động (tổng quan)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf9de0",
   "metadata": {},
   "source": [
    "LLM là một mô hình học sâu (deep learning) dựa trên kiến trúc Transformer. Cơ bản, nó hoạt động theo cơ chế:\n",
    "\n",
    "👉 Dự đoán từ tiếp theo trong chuỗi văn bản, dựa trên ngữ cảnh phía trước.\n",
    "\n",
    "⚙️ Các bước chính:\n",
    "- Tiền xử lý dữ liệu văn bản (tokenization)\n",
    "\n",
    "- Biểu diễn chuỗi thành vector số\n",
    "\n",
    "- Mạng neural học các mối liên hệ ngữ cảnh giữa các từ (attention)\n",
    "\n",
    "- Sinh ra từ mới, lặp lại để tạo thành câu trả lời hoàn chỉnh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191d9ca",
   "metadata": {},
   "source": [
    "<h3>🏗️ 3. Vì sao gọi là “Large” (Lớn)?</h3>\n",
    "“Large” thể hiện:\n",
    "\n",
    "✅ Số lượng tham số cực lớn (GPT-3 có 175 tỷ tham số)\n",
    "\n",
    "✅ Dữ liệu huấn luyện khổng lồ (hàng trăm GB đến hàng TB văn bản)\n",
    "\n",
    "✅ Hiệu năng vượt trội trên nhiều tác vụ ngôn ngữ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c1e4f",
   "metadata": {},
   "source": [
    "<h3>📚 4. Các mô hình LLM tiêu biểu</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9b5d8",
   "metadata": {},
   "source": [
    "| Tên mô hình | Tổ chức phát triển | Đặc điểm nổi bật |\n",
    "|-------------|---------------------|------------------|\n",
    "| **GPT-3.5 / GPT-4** | OpenAI | ChatGPT đang dùng |\n",
    "| **Claude** | Anthropic | An toàn, định hướng đạo đức |\n",
    "| **LLaMA 2 / 3** | Meta (Facebook) | Mã nguồn mở |\n",
    "| **Mistral / Mixtral** | Mistral AI | Nhẹ, hiệu quả cao |\n",
    "| **Gemini (Bard)** | Google | Tích hợp với hệ sinh thái Google |\n",
    "| **PaLM 2 / Gemini 1.5** | Google DeepMind | NLP đa ngôn ngữ, toán học |\n",
    "| **Command R+** | Cohere | Dùng cho RAG, QA |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ef783",
   "metadata": {},
   "source": [
    "<h3>🔎 5. Ứng dụng của LLM trong thực tế</h3>\n",
    "\n",
    "💬 Chatbot (ChatGPT, Claude, Gemini)\n",
    "\n",
    "📝 Viết nội dung (blog, email, marketing…)\n",
    "\n",
    "🧠 Trợ lý học tập và giảng dạy\n",
    "\n",
    "🧾 Tóm tắt văn bản, phân tích dữ liệu\n",
    "\n",
    "🧑‍💻 Viết code, phân tích mã nguồn\n",
    "\n",
    "🌍 Dịch ngôn ngữ, xử lý ngôn ngữ đa ngữ\n",
    "\n",
    "🤖 Tự động hóa quy trình doanh nghiệp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a837102",
   "metadata": {},
   "source": [
    "<h3>📌 6. Một số đặc điểm quan trọng của LLM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d1953",
   "metadata": {},
   "source": [
    "| Đặc điểm | Mô tả |\n",
    "|----------|------|\n",
    "| **Không cần huấn luyện lại** | Chỉ cần prompt để điều khiển |\n",
    "| **Tính linh hoạt cao** | Có thể dùng cho nhiều nhiệm vụ khác nhau |\n",
    "| **Dựa trên dữ liệu huấn luyện** | Không có \"ý thức\", chỉ phản hồi dựa vào mẫu đã học |\n",
    "| **Có thể tạo ra lỗi hoặc ảo giác** | Đôi khi mô hình tạo ra thông tin sai (gọi là hallucination) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c1fa5",
   "metadata": {},
   "source": [
    "<h3>🛠️ 7. Một số kỹ thuật nâng cao với LLM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f0f69",
   "metadata": {},
   "source": [
    "- Prompt engineering: Thiết kế prompt hiệu quả để điều khiển đầu ra\n",
    "\n",
    "- Few-shot / Zero-shot learning: Học từ vài ví dụ hoặc không cần ví dụ\n",
    "\n",
    "- Fine-tuning: Tinh chỉnh mô hình cho nhiệm vụ cụ thể\n",
    "\n",
    "- RAG (Retrieval-Augmented Generation): Kết hợp LLM với tìm kiếm dữ liệu\n",
    "\n",
    "- RLHF (Reinforcement Learning from Human Feedback): Cải thiện phản hồi dựa trên đánh giá con người"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8df37",
   "metadata": {},
   "source": [
    "<h3>Few-shot learning </h3> (học với ít mẫu) là một kỹ thuật trong lĩnh vực trí tuệ nhân tạo (AI) và học máy (machine learning), nơi mô hình có thể học và thực hiện một nhiệm vụ mới chỉ với một số ít ví dụ được cung cấp — đôi khi chỉ 1, 5 hoặc 10 mẫu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15945c17",
   "metadata": {},
   "source": [
    "🤖 Trong các mô hình như GPT (ChatGPT, GPT-4...):\n",
    "\n",
    "Few-shot learning xảy ra ngay trong prompt.\n",
    "\n",
    "Không cần huấn luyện lại mô hình, chỉ cần soạn prompt thông minh chứa ví dụ là mô hình có thể làm theo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
